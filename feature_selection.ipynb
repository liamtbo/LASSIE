{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "015d1da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import plotting\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6902a362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_src):\n",
    "    curve_data = [] # used for plotting\n",
    "    filename_list = []\n",
    "    for filename in os.listdir(data_src):\n",
    "        df = pd.read_csv(f\"{data_src}/{filename}\")\n",
    "        curve_data.append(df)\n",
    "        filename_list.append(filename)\n",
    "    return curve_data, filename_list\n",
    "\n",
    "data_src = \"data/cleaned_data\"\n",
    "curve_data, filename_list = load_data(data_src)\n",
    "filename_to_depth_resist = dict(zip(filename_list, curve_data))\n",
    "\n",
    "data_features = pd.read_csv(\"data/features.csv\")\n",
    "\n",
    "ylabel_name = 'marions_ylabels'\n",
    "ylabel_to_cluster_num = {'ES-B':0, 'ES-BW':1, 'ES-S':2, 'ES-S-Plates':3, 'ES-D':4, 'LS':5, 'F':6, 'LS/F':7, 'ES-DB':8, 'ES': 9}\n",
    "data_features[f'{ylabel_name}_nums'] = data_features[ylabel_name].map(ylabel_to_cluster_num)\n",
    "labeled_data = data_features[data_features[ylabel_name].notna()].copy() # removes NaN's which correspond to non-labled data\n",
    "labeled_num_features = plotting.extract_numerical_features(labeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "177d226d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: -0.47\n",
      "Silhouette Score: -0.39\n",
      "Silhouette Score: -0.39\n",
      "Silhouette Score: -0.37\n",
      "Silhouette Score: -0.42\n",
      "Silhouette Score: -0.39\n",
      "Silhouette Score: -0.34\n",
      "Silhouette Score: -0.37\n",
      "Silhouette Score: -0.34\n",
      "Silhouette Score: -0.36\n",
      "Silhouette Score: -0.41\n",
      "Silhouette Score: -0.38\n",
      "Silhouette Score: -0.34\n",
      "Silhouette Score: -0.36\n",
      "Silhouette Score: -0.34\n",
      "Silhouette Score: -0.37\n",
      "Silhouette Score: -0.39\n",
      "Silhouette Score: -0.35\n",
      "Silhouette Score: -0.38\n",
      "Silhouette Score: -0.39\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from sklearn.metrics import mutual_info_score, adjusted_rand_score\n",
    "\n",
    "combs = list(itertools.combinations(labeled_num_features.columns, 3))\n",
    "for comb in combs:\n",
    "    X = labeled_num_features[list(comb)].to_numpy()\n",
    "    labels = labeled_data[f'{ylabel_name}_nums'].to_numpy()\n",
    "    # Calculate clustering metrics\n",
    "    silhouette = silhouette_score(X, labels)\n",
    "    # db_index = davies_bouldin_score(X, kmeans.labels_)\n",
    "    # ch_index = calinski_harabasz_score(X, kmeans.labels_)\n",
    "    # ari = adjusted_rand_score(iris.target, kmeans.labels_)\n",
    "    # mi = mutual_info_score(iris.target, kmeans.labels_)\n",
    "\n",
    "    # Print the metric scores\n",
    "    print(f\"Silhouette Score: {silhouette:.2f}\")\n",
    "    # print(f\"Davies-Bouldin Index: {db_index:.2f}\")\n",
    "    # print(f\"Calinski-Harabasz Index: {ch_index:.2f}\")\n",
    "    # print(f\"Adjusted Rand Index: {ari:.2f}\")\n",
    "    # print(f\"Mutual Information (MI): {mi:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
