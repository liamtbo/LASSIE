{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d25e20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['resistance_depth_15.csv', 'resistance_depth_36.csv', 'resistance_depth_50.csv', 'resistance_depth_54.csv', 'resistance_depth_25.csv', 'resistance_depth_69.csv', 'resistance_depth_67.csv', 'resistance_depth_46.csv', 'resistance_depth_1.csv', 'resistance_depth_49.csv', 'resistance_depth_45.csv', 'resistance_depth_4.csv', 'resistance_depth_44.csv', 'resistance_depth_59.csv', 'resistance_depth_64.csv', 'resistance_depth_0.csv', 'resistance_depth_21.csv', 'resistance_depth_71.csv', 'resistance_depth_53.csv', 'resistance_depth_20.csv', 'resistance_depth_75.csv', 'resistance_depth_43.csv', 'resistance_depth_61.csv', 'resistance_depth_40.csv', 'resistance_depth_24.csv', 'resistance_depth_62.csv', 'resistance_depth_65.csv', 'resistance_depth_47.csv', 'resistance_depth_41.csv', 'resistance_depth_13.csv', 'resistance_depth_51.csv', 'resistance_depth_5.csv', 'resistance_depth_2.csv', 'resistance_depth_26.csv', 'resistance_depth_38.csv', 'resistance_depth_63.csv', 'resistance_depth_9.csv', 'resistance_depth_76.csv', 'resistance_depth_23.csv', 'resistance_depth_56.csv', 'resistance_depth_10.csv', 'resistance_depth_34.csv', 'resistance_depth_3.csv', 'resistance_depth_6.csv', 'resistance_depth_11.csv', 'resistance_depth_7.csv', 'resistance_depth_39.csv', 'resistance_depth_48.csv', 'resistance_depth_16.csv', 'resistance_depth_68.csv', 'resistance_depth_74.csv', 'resistance_depth_32.csv', 'resistance_depth_14.csv', 'resistance_depth_70.csv', 'resistance_depth_12.csv', 'resistance_depth_73.csv', 'resistance_depth_52.csv', 'resistance_depth_22.csv', 'resistance_depth_27.csv', 'resistance_depth_35.csv', 'resistance_depth_33.csv', 'resistance_depth_42.csv', 'resistance_depth_55.csv', 'resistance_depth_79.csv', 'resistance_depth_28.csv', 'resistance_depth_60.csv', 'resistance_depth_18.csv', 'resistance_depth_30.csv', 'resistance_depth_78.csv', 'resistance_depth_37.csv', 'resistance_depth_19.csv', 'resistance_depth_31.csv', 'resistance_depth_57.csv', 'resistance_depth_29.csv', 'resistance_depth_58.csv', 'resistance_depth_17.csv', 'resistance_depth_77.csv', 'resistance_depth_66.csv', 'resistance_depth_72.csv', 'resistance_depth_8.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_list = []\n",
    "filename_list = []\n",
    "for filename in os.listdir(\"/home/frankwoods/Desktop/lassie/data/ws23_processed_data\"):\n",
    "    df = pd.read_csv(f\"/home/frankwoods/Desktop/lassie/data/ws23_processed_data/{filename}\")\n",
    "    filename_list.append(filename)\n",
    "    df_list.append(df)\n",
    "print(filename_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13b4f942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example:     res_mean    res_max        slope  depth_max\n",
      "0  18.478468  36.954578  3363.366328   0.010987\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_features(df):\n",
    "    res = df[\"resistance\"]\n",
    "    dep = df[\"depth\"]\n",
    "    return pd.DataFrame([{\n",
    "        \"res_mean\": res.mean(),\n",
    "        \"res_max\": res.max(),\n",
    "        \"slope\": res.max() / dep.max(),\n",
    "        \"depth_max\": dep.max(),\n",
    "    }])\n",
    "\n",
    "# shape (n,m) where n is number of df and m is extracted feaetures\n",
    "representation_list = []\n",
    "for df in df_list:\n",
    "    representation_list.append(extract_features(df))\n",
    "print(f\"example: {representation_list[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a831a9",
   "metadata": {},
   "source": [
    "# Visualize Extracted Features Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a1ba7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "representation_df  = pd.concat(representation_list, axis=0, ignore_index=True)\n",
    "# # print(representation_df)\n",
    "def plot_feature_dist(representation_df):\n",
    "    for col in representation_df.columns:\n",
    "        plt.hist(representation_df[col], bins=60, density=True)\n",
    "        plt.title(f\"Extracted Feature {col} Global Histogram\")\n",
    "        plt.show()\n",
    "# plot_feature_dist(representation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e52a5db",
   "metadata": {},
   "source": [
    "# Scale Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35451635",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "def transform_features(df):\n",
    "    df = df.copy()  # avoid modifying original\n",
    "    # Apply cube root to 'slope'\n",
    "    if \"slope\" in df.columns: df['slope'] = np.log(df['slope'])\n",
    "    # if \"skew\" in df.columns: df[\"skew\"] = df[\"skew\"] ** 1.1\n",
    "    # if \"kurtosis\" in df.columns: df[\"kurtosis\"] = np.sqrt(df[\"kurtosis\"]) \n",
    "    # Standardize\n",
    "    scaler = StandardScaler()\n",
    "    df[df.columns] = scaler.fit_transform(df[df.columns])\n",
    "    return df\n",
    "\n",
    "scaled_representations = transform_features(representation_df)\n",
    "# plot_feature_dist(scaled_representations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878e3560",
   "metadata": {},
   "source": [
    "# Analyze Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a33ba8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           res_mean   res_max     slope  depth_max\n",
      "res_mean   1.000000  0.967517  0.898150  -0.829894\n",
      "res_max    0.967517  1.000000  0.927126  -0.852263\n",
      "slope      0.898150  0.927126  1.000000  -0.953341\n",
      "depth_max -0.829894 -0.852263 -0.953341   1.000000\n"
     ]
    }
   ],
   "source": [
    "corr_matrix = scaled_representations.corr()\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73a2c3f",
   "metadata": {},
   "source": [
    "# Save representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "248dd816",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_representations.to_csv(f\"data/features_extracted.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
