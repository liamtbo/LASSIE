{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1f705e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'plotting_feature_extraction' from '/home/liam-bouffard/Desktop/LASSIE/plotting_dir/plotting_feature_extraction.py'>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"plotting_dir\")\n",
    "import plotting_feature_extraction\n",
    "import importlib\n",
    "importlib.reload(plotting_feature_extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5d25e20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WS23_L1_T1_P_10.csv', 'WS23_L3_T1_P_10.csv', 'WS23_L3_T1_P_6.csv', 'WS23_L3_T1_P_1.csv', 'WS23_L3_T1_P_8.csv', 'WS23_L1_T1_P_17.csv', 'WS23_L3_T1_P_31.csv', 'WS23_L1_T1_P_6.csv', 'WS23_L1_T1_P_7.csv', 'WS25_Aug5_Loc1A_T1_F17_1029.csv', 'WS25_Aug5_Loc1A_T1_F6_0930.csv', 'WS25_Aug6_Loc1A_T1_F32_0714.csv', 'WS25_Aug5_Loc1A_T1_F12_1010.csv', 'WS23_L3_T1_P_0.csv', 'WS23_L1_T1_P_2.csv', 'WS23_L1_T1_P_8.csv', 'WS25_Aug5_Loc1A_T1_F8_0955.csv', 'WS23_L3_T1_P_24.csv', 'WS25_Aug5_Loc1A_T1_F5_0929.csv', 'WS23_L3_T1_P_18.csv', 'WS25_Aug6_Loc1A_T1_F20_0643_attempt3.csv', 'WS23_L1_T1_P_19.csv', 'WS23_L2_T1_P_2.csv', 'WS23_L1_T1_P_16.csv', 'WS23_L1_T1_P_1.csv', 'WS25_Aug5_Loc1A_T1_F24_1057.csv', 'WS23_L3_T1_P_4.csv', 'WS25_Aug5_Loc1A_T1_F16_1028.csv', 'WS23_L1_T1_P_18.csv', 'WS23_L3_T1_P_13.csv', 'WS23_L3_T1_P_16.csv', 'WS25_Aug6_Loc1A_T1_F23_0656.csv', 'WS23_L2_T1_P_13.csv', 'WS23_L2_T1_P_5.csv', 'WS23_L1_T1_P_3.csv', 'WS25_Aug6_Loc1A_T1_F18_0624.csv', 'WS23_L1_T1_P_22.csv', 'WS23_L2_T1_P_7.csv', 'WS23_L1_T1_P_14.csv', 'WS23_L3_T1_P_33.csv', 'WS25_Aug5_Loc1A_T1_F3_0926.csv', 'WS23_L2_T2_P_3.csv', 'WS23_L1_T1_P_9.csv', 'WS25_Aug5_Loc1A_T1_F14_1024_A2.csv', 'WS23_L3_T1_P_5.csv', 'WS23_L3_T1_P_3.csv', 'WS25_Aug5_Loc1A_T1_F15_1026.csv', 'WS25_Aug6_Loc1A_T1_F29_0706.csv', 'WS23_L3_T1_P_2.csv', 'WS25_Aug5_Loc1A_T1_F13_1012.csv', 'WS23_L2_T1_P_16.csv', 'WS23_L2_T1_P_9.csv', 'WS25_Aug5_Loc1A_T1_F7_0952.csv', 'WS23_L2_T1_P_1.csv', 'WS25_Aug6_Loc1A_T1_F26_0700.csv', 'WS25_Aug5_Loc1A_T1_F2_0919.csv', 'WS23_L1_T1_P_0.csv', 'WS23_L3_T1_P_26.csv', 'WS25_Aug6_Loc1A_T1_F27_0702.csv', 'WS25_Aug5_Loc1A_T1_F11_1008.csv', 'WS23_L2_T1_P_14.csv', 'WS23_L2_T1_P_3.csv', 'WS23_L3_T1_P_9.csv', 'WS23_L3_T1_P_15.csv', 'WS23_L3_T1_P_11.csv', 'WS23_L1_T1_P_23.csv', 'WS23_L1_T1_P_13.csv', 'WS23_L1_T1_P_4.csv', 'WS25_Aug5_Loc1A_T1_F4_0927.csv', 'WS25_Aug6_Loc1A_T1_F31_0711.csv', 'WS23_L3_T1_P_25.csv', 'WS25_Aug6_Loc1A_T1_F21_0648_attempt2.csv', 'WS23_L2_T1_P_4.csv', 'WS23_L3_T1_P_14.csv', 'WS23_L2_T1_P_11.csv', 'WS23_L1_T1_P_15.csv', 'WS23_L1_T1_P_5.csv', 'WS25_Aug6_Loc1A_T1_F30_0709.csv', 'WS23_L3_T1_P_27.csv', 'WS23_L2_T1_P_15.csv', 'WS23_L2_T1_P_17.csv', 'WS23_L3_T1_P_23.csv', 'WS23_L2_T1_P_10.csv', 'WS23_L3_T1_P_19.csv', 'WS25_Aug5_Loc1A_T1_F10_0958.csv', 'WS25_Aug6_Loc1A_T1_F22_0653.csv', 'WS23_L1_T1_P_21.csv', 'WS23_L2_T2_P_1.csv', 'WS23_L2_T1_P_12.csv', 'WS25_Aug6_Loc1A_T1_F19_0629.csv', 'WS23_L2_T2_P_2.csv', 'WS23_L2_T1_P_8.csv', 'WS23_L2_T1_P_6.csv', 'WS25_Aug5_Loc1A_T1_F28_1101.csv', 'WS23_L3_T1_P_7.csv', 'WS23_L2_T2_P_0.csv', 'WS23_L1_T1_P_11.csv', 'WS23_L3_T1_P_29.csv', 'WS25_Aug5_Loc1A_T1_F25_1058.csv', 'WS23_L3_T1_P_32.csv', 'WS25_Aug5_Loc1A_T1_F1_0918.csv', 'WS23_L3_T1_P_17.csv', 'WS23_L3_T1_P_12.csv', 'WS23_L2_T2_P_4.csv', 'WS23_L3_T1_P_20.csv', 'WS23_L1_T1_P_20.csv', 'WS23_L3_T1_P_22.csv', 'WS23_L1_T1_P_12.csv', 'WS25_Aug5_Loc1A_T1_F9_0957.csv', 'WS23_L3_T1_P_21.csv']\n",
      "        depth  resistance\n",
      "0    0.000000    0.000000\n",
      "1    0.000024    0.030256\n",
      "2    0.000047    0.057511\n",
      "3    0.000071    0.077612\n",
      "4    0.000095    0.093626\n",
      "..        ...         ...\n",
      "495  0.011740   35.158353\n",
      "496  0.011764   35.131210\n",
      "497  0.011788   35.108666\n",
      "498  0.011812   35.111194\n",
      "499  0.011835   35.079865\n",
      "\n",
      "[500 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "curves_data = []\n",
    "filename_list = []\n",
    "for filename in os.listdir(\"data/cleaned_data\"):\n",
    "    df = pd.read_csv(f\"data/cleaned_data/{filename}\").drop(columns=[\"Unnamed: 0\"])\n",
    "    filename_list.append(filename)\n",
    "    curves_data.append(df)\n",
    "print(filename_list)\n",
    "print(curves_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27333d00",
   "metadata": {},
   "source": [
    "# Find Curve Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "916e5f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_curve_shape(df):\n",
    "    x = df['depth'].to_numpy()\n",
    "    y = df['resistance'].to_numpy()\n",
    "    # create evenly spaces points\n",
    "    chord = np.linspace(df['resistance'].iloc[0], df['resistance'].iloc[-1], num=len(df['depth']))\n",
    "    y_diff = y - chord # makes chord the x-axis, any y_points above chord are pos, below are neg\n",
    "    return np.trapezoid(y=y_diff, x=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb52604",
   "metadata": {},
   "source": [
    "# Find Force-Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4204db47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_force_drop_subranges(df: pd.DataFrame, percent_of_max_resistance: float):\n",
    "    down_moves_subrange_list = []\n",
    "    resistance_max = df['resistance'].max()\n",
    "    min_drop_size = resistance_max * percent_of_max_resistance\n",
    "    curr_peak_idx = 0\n",
    "    curr_trough_idx = 0\n",
    "    in_drop_subrange = 0 # bool\n",
    "\n",
    "    for idx in range(1, len(df['resistance'])):\n",
    "        curr_peak = df['resistance'].iloc[curr_peak_idx]\n",
    "        curr_trough = df['resistance'].iloc[curr_trough_idx]\n",
    "        curr_resistance = df['resistance'].iloc[idx]\n",
    "\n",
    "        if curr_resistance >= curr_peak and in_drop_subrange:\n",
    "            in_drop_subrange = 0\n",
    "            down_moves_subrange_list.append((curr_peak_idx, curr_trough_idx))\n",
    "\n",
    "        if curr_resistance >= curr_peak:\n",
    "            curr_peak_idx = idx\n",
    "            curr_trough_idx = idx\n",
    "        elif curr_peak - curr_resistance >= min_drop_size and curr_resistance < curr_trough: \n",
    "            in_drop_subrange = 1\n",
    "            curr_trough_idx = idx\n",
    "    \n",
    "    if in_drop_subrange: down_moves_subrange_list.append((curr_peak_idx, curr_trough_idx)) \n",
    "            \n",
    "    return down_moves_subrange_list\n",
    "\n",
    "def find_largest_force_drop(df: pd.DataFrame, subrange_list: List[Tuple]):\n",
    "    curr_max_drop_size = 0\n",
    "    curr_max_subrange_idxs = (0,0)\n",
    "    for subrange_start, subrange_end in subrange_list:\n",
    "        subrange_diff = df['resistance'].iloc[subrange_start] - df['resistance'].iloc[subrange_end]\n",
    "        if subrange_diff > curr_max_drop_size: \n",
    "            curr_max_drop_size = subrange_diff\n",
    "            curr_max_subrange_idxs = (subrange_start, subrange_end)\n",
    "    return curr_max_drop_size, curr_max_subrange_idxs\n",
    "\n",
    "def plot(curves_data: List[pd.DataFrame], plot_idx_range: List[int], title: str = 'Depth vs Resistance'):\n",
    "\n",
    "    all_depth_resistance_data = pd.concat(curves_data, axis=0, ignore_index=True)\n",
    "    gloabl_max_depth = all_depth_resistance_data['depth'].max()\n",
    "    gloabl_max_resistance = all_depth_resistance_data['resistance'].max()\n",
    "\n",
    "    for idx in plot_idx_range:\n",
    "\n",
    "        print(f\"plot idx: {idx}\")\n",
    "\n",
    "        df = curves_data[idx]\n",
    "        percent = 0.1\n",
    "        subranges = find_force_drop_subranges(df, percent)\n",
    "        print(f\"max_resistance: {df['resistance'].max()}\")\n",
    "        print(f\"subranges: {[(float(df['resistance'].iloc[start]), float(df['resistance'].iloc[end])) for start, end in subranges]}\")\n",
    "   \n",
    "        plt.figure(figsize=(5, 3))\n",
    "        plt.xlim(0,gloabl_max_depth)\n",
    "        plt.ylim(0,gloabl_max_resistance)\n",
    "        plt.plot([0,df['depth'].max()], [0,df['resistance'].iloc[df['depth'].values.argmax()]], color='red')\n",
    "        plt.plot([0,df['depth'].max()], [0,df['resistance'].iloc[df['depth'].values.argmax()]], color='red')\n",
    "        plt.plot([0,df['depth'].max()], [0,df['resistance'].iloc[df['depth'].values.argmax()]], color='red')\n",
    "\n",
    "        # Plot full depth vs resistance line\n",
    "        plt.plot(df['depth'], df['resistance'],linestyle='-')\n",
    "        plt.xlabel('Depth (m)')\n",
    "        plt.ylabel('Resistance (N)')\n",
    "        plt.title(f\"{title} - Plot {idx}\")\n",
    "        # plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5b7ee952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_koverall(curve):\n",
    "    return np.polyfit(curve['depth'], curve['resistance'], 1)[0]\n",
    "\n",
    "def find_k2cm(curve):\n",
    "    curve = curve[curve['depth'] <= 0.02]\n",
    "    if curve['depth'].max() < 0.019: return 0 # 0.019 bc most data doesn't have a perfect 0.02 depth\n",
    "    return np.polyfit(curve['depth'], curve['resistance'], 1)[0]\n",
    "\n",
    "def find_ksurface(curve):\n",
    "    pass\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "def find_rsquared(curve):\n",
    "    coeffs = np.polyfit(curve['depth'], curve['resistance'], 1)\n",
    "    predicted = np.polyval(coeffs, curve['depth'])\n",
    "    actual = curve['resistance']\n",
    "    return r2_score(actual, predicted)\n",
    "\n",
    "def find_heterogenity(curve):\n",
    "    pass\n",
    "\n",
    "def find_work2cm(curve):\n",
    "    if curve['resistance'].max() < 0.2: return 0\n",
    "    depth_m = curve['depth'] * 1000.0  # convert m → mm\n",
    "    work = np.trapezoid(curve['resistance'], depth_m)\n",
    "    return work \n",
    "\n",
    "def find_Fpeak(curve):\n",
    "    return curve['resistance'].max()\n",
    "\n",
    "def find_dpeak(curve):\n",
    "    return curve.loc[curve['resistance'].idxmax(), 'depth']\n",
    "\n",
    "def find_Fbasin(curve):\n",
    "    pass\n",
    "\n",
    "def find_dbasin(curve):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6915d25",
   "metadata": {},
   "source": [
    "# Choose Features\n",
    "IMPORTANT: If you add variables here, you must add the names to the top of plotting.py file as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "13b4f942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['depth_max', 'largest_force_drop_size', 'curve_first_quarter_slope',\n",
      "       'force_mean', 'rsquared'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def extract_simple_features(df):\n",
    "    res = df[\"resistance\"]\n",
    "    dep = df[\"depth\"]\n",
    "    max_res_drop_val, max_res_drop_subrange_idxs = find_largest_force_drop(df, find_force_drop_subranges(df, 0.001))\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        # \"curve_overall_slope\": [res.max() / dep.max()],\n",
    "        \"depth_max\": [dep.max()],\n",
    "        # \"force_max\": [res.max()],\n",
    "        # \"num_peaks\": len(find_force_drop_subranges(df,0.1)) / dep.max(),\n",
    "        \"largest_force_drop_size\": max_res_drop_val,\n",
    "        # \"largest_force_drop_dep\": dep.loc[max_res_drop_subrange_idxs[0]],\n",
    "        # \"largest_force_drop_res\": res.loc[max_res_drop_subrange_idxs[0]],\n",
    "        # \"curve_shape\": find_curve_shape(df),\n",
    "# \n",
    "        \"curve_first_quarter_slope\": (res.loc[round(0.25 * len(res))] - res.min()) / (dep.loc[round(0.25 * len(dep))] - dep.min()),\n",
    "        # \"curve_second_quarter_slope\": (res.loc[round(0.50 * len(res))] - res.loc[round(0.25 * len(res))]) / (dep.loc[round(0.50 * len(dep))] - dep.loc[round(0.25 * len(dep))]),\n",
    "        # \"curve_third_quarter_slope\": (res.loc[round(0.75 * len(res))] - res.loc[round(0.50 * len(res))]) / (dep.loc[round(0.75 * len(dep))] - dep.loc[round(0.50 * len(dep))]),\n",
    "        # \"curve_fourth_quarter_slope\": (res.max() - res.loc[round(0.75 * len(res))]) / (dep.max() - dep.loc[round(0.75 * len(dep))]),\n",
    "# \n",
    "        # resistance statistics\n",
    "        # \"force_quartile_1\": res.quantile(0.25),\n",
    "        # \"force_quartile_2\": res.quantile(0.50),\n",
    "        # \"force_quartile_3\": res.quantile(0.75),\n",
    "        # \"force_variance\": res.var(),\n",
    "        \"force_mean\": res.mean(),\n",
    "        # \"force_skew\": res.skew(), # measurs asymmetry of a distribution around it's mean\n",
    "        # \"force_kurtosis\": res.kurt(), # descirbes tailedness or peakedness of a distribution\n",
    "# \n",
    "        # USC's Feature Set\n",
    "        # \"k_overall\": find_koverall(df),\n",
    "        # \"curve_2cm_slope\": find_k2cm(df),\n",
    "        \"rsquared\": find_rsquared(df),\n",
    "    })\n",
    "\n",
    "\n",
    "# shape (n,m) where n is number of df and m is extracted feaetures\n",
    "representation_list = []\n",
    "for i, df in enumerate(curves_data):\n",
    "    extracted_simple_features = extract_simple_features(df)\n",
    "    representation_list.append(extracted_simple_features)\n",
    "print(f\"{representation_list[0].columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca7b20d",
   "metadata": {},
   "source": [
    "# Examples of what Features Are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4a91c42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # here use plot feature extraction\n",
    "# feature_names = ['largest_force_drop_size', 'force_mean', 'force_quartile_2',\n",
    "#        'curve_first_quarter_slope', 'force_quartile_3', 'rsquared',\n",
    "#        'force_quartile_1', 'force_variance', 'force_max', 'curve_2cm_slope',\n",
    "#        'depth_max', 'curve_overall_slope', 'largest_force_drop_force',\n",
    "#        'num_peaks', 'curve_third_quarter_slope', 'curve_shape',\n",
    "#        'largest_force_drop_dep', 'curve_second_quarter_slope', 'force_skew',\n",
    "#        'curve_fourth_quarter_slope', 'force_kurtosis']\n",
    "# # plotting_feature_extraction.plot_feature_selection_seperately(\n",
    "# #     feature_names, curves_data, 0,\n",
    "# # )\n",
    "# plotting_feature_extraction.plot_feature_selection(\n",
    "#     feature_names, curves_data, 4,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b10be5d",
   "metadata": {},
   "source": [
    "# Save the names of the numerical feature's used for clustering.\n",
    "This is imported in plotting.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ac5aea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_feature_names = pd.Series(representation_list[0].columns.tolist(), name='numerical_feature_names')\n",
    "numerical_feature_names.to_csv('data/numerical_feature_names.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a831a9",
   "metadata": {},
   "source": [
    "# Visualize Extracted Features Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "596d13d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "representation_df = pd.concat(representation_list, axis=0)\n",
    "\n",
    "# def plot_feature_dist(representation_df):\n",
    "#     # for col in representation_df.columns:\n",
    "#     # x, y = plotting_feature_extraction.find_oriented_subplot_dims(len(representation_df.columns))\n",
    "#     x, y = plotting_feature_extraction.find_subplot_dims_orientation(len(representation_df.columns))\n",
    "#     fig, axs = plt.subplots(x,y,figsize=(round(x*2), round(y*5)))\n",
    "#     # fig.suptitle('Feature Histograms')\n",
    "#     for i, ax in enumerate(axs.flatten()):\n",
    "#         if i > len(representation_df.columns)-1: break\n",
    "#         col = representation_df.columns[i]\n",
    "#         ax.hist(representation_df[col], bins=60, density=True)\n",
    "#         ax.set_title(f\"{col.title()} Histogram\", fontsize=12)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# plot_feature_dist(representation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e52a5db",
   "metadata": {},
   "source": [
    "# Scale Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "35451635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_features(df):\n",
    "    df = df.copy()  # avoid modifying original\n",
    "    scaler = StandardScaler()\n",
    "    df[df.columns] = scaler.fit_transform(df[df.columns])\n",
    "    return df\n",
    "\n",
    "scaled_representations = transform_features(representation_df)\n",
    "# plot_feature_dist(scaled_representations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99ccaf3",
   "metadata": {},
   "source": [
    "# Add Meta-Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7b626c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_representations['filenames'] = filename_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468d4201",
   "metadata": {},
   "source": [
    "### Add Marion's y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d9eaafc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['depth_max', 'largest_force_drop_size', 'curve_first_quarter_slope',\n",
      "       'force_mean', 'rsquared', 'filenames'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "marions_filenames_to_ylabels = {\n",
    "    \"WS23_L2_T1_P_0.csv\": 'LS', \"WS23_L2_T1_P_1.csv\": 'LS', \"WS23_L2_T1_P_2.csv\": 'LS', \"WS23_L2_T1_P_3.csv\": 'ES-D', \"WS23_L2_T1_P_4.csv\": \"LS\", \"WS23_L2_T1_P_5.csv\": \"ES-D\",\n",
    "    \"WS23_L2_T1_P_6.csv\": \"ES-D\", \"WS23_L2_T1_P_7.csv\": \"ES-D\", \"WS23_L2_T1_P_8.csv\": \"ES-DB\", \"WS23_L2_T1_P_9.csv\": \"ES-S\", \"WS23_L2_T1_P_10.csv\": \"ES-D\", \"WS23_L2_T1_P_11.csv\": 'ES-D',\n",
    "    \"WS23_L2_T1_P_12.csv\": 'ES-S', \"WS23_L2_T1_P_13.csv\": 'ES-D', \"WS23_L2_T1_P_14.csv\": 'ES-S', \"WS23_L2_T1_P_15.csv\": 'ES-D', \"WS23_L2_T1_P_16.csv\": 'ES-DB', \"WS23_L2_T1_P_17.csv\": 'ES-S',\n",
    "\n",
    "    \"WS23_L3_T1_P_0.csv\": 'LS', \"WS23_L3_T1_P_1.csv\": 'ES-B', \"WS23_L3_T1_P_2.csv\": 'ES-B', \"WS23_L3_T1_P_3.csv\": 'ES-S',\n",
    "    \"WS23_L3_T1_P_4.csv\": 'ES-B', \"WS23_L3_T1_P_5.csv\": 'ES-B', \"WS23_L3_T1_P_6.csv\": 'ES-BW', \"WS23_L3_T1_P_7.csv\": 'ES-B',\n",
    "    \"WS23_L3_T1_P_8.csv\": 'ES-BW', \"WS23_L3_T1_P_9.csv\": 'F', \"WS23_L3_T1_P_10.csv\": 'ES-D', \"WS23_L3_T1_P_11.csv\": 'ES',\n",
    "    \"WS23_L3_T1_P_12.csv\": 'F', \"WS23_L3_T1_P_13.csv\": 'F', \"WS23_L3_T1_P_14.csv\": 'ES-D', \"WS23_L3_T1_P_15.csv\": 'ES-D',\n",
    "    \"WS23_L3_T1_P_16.csv\": 'ES-B', \"WS23_L3_T1_P_17.csv\": 'ES', \"WS23_L3_T1_P_18.csv\": 'ES-S-Plates', \"WS23_L3_T1_P_19.csv\": 'ES-S-Plates',\n",
    "    \"WS23_L3_T1_P_20.csv\": 'LS/F', \"WS23_L3_T1_P_21.csv\": 'ES', \"WS23_L3_T1_P_22.csv\": 'ES', \"WS23_L3_T1_P_23.csv\": 'LS'\n",
    "}\n",
    "print(scaled_representations.columns)\n",
    "scaled_representations['marions_ylabels'] = scaled_representations['filenames'].map(marions_filenames_to_ylabels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9ea6b0",
   "metadata": {},
   "source": [
    "### Add label creation meta-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "893e102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "popcorn_filenames = ['WS23_L3_T1_P_0.csv', 'WS23_L3_T1_P_1.csv', 'WS23_L3_T1_P_2.csv', 'WS23_L3_T1_P_3.csv', \n",
    "    'WS23_L3_T1_P_4.csv', 'WS23_L3_T1_P_5.csv', 'WS23_L3_T1_P_6.csv', 'WS23_L3_T1_P_7.csv', \n",
    "    'WS23_L3_T1_P_8.csv', 'WS23_L3_T1_P_9.csv', 'WS23_L3_T1_P_10.csv', 'WS23_L3_T1_P_11.csv', \n",
    "    'WS23_L3_T1_P_12.csv', 'WS23_L3_T1_P_13.csv', 'WS23_L3_T1_P_14.csv', 'WS23_L3_T1_P_15.csv', \n",
    "    'WS23_L3_T1_P_16.csv', 'WS23_L3_T1_P_17.csv', 'WS23_L3_T1_P_18.csv', 'WS23_L3_T1_P_19.csv', \n",
    "    'WS23_L3_T1_P_20.csv', 'WS23_L3_T1_P_21.csv', 'WS23_L3_T1_P_22.csv', 'WS23_L3_T1_P_23.csv']\n",
    "\n",
    "popcorn = [False,True,True,False,True,True,True,True,True,False,False,False,False,False,False,False,False,False,False,False,False,False,False,False]\n",
    "\n",
    "filenames_to_popcorn = dict(zip(popcorn_filenames, popcorn))\n",
    "scaled_representations['popcorn'] = scaled_representations['filenames'].map(filenames_to_popcorn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77b7e2d",
   "metadata": {},
   "source": [
    "### Add feet from dune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7888daf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_list = ['WS23_L1_T1_P_0.csv', 'WS23_L1_T1_P_1.csv', 'WS23_L1_T1_P_2.csv', 'WS23_L1_T1_P_3.csv', 'WS23_L1_T1_P_4.csv', 'WS23_L1_T1_P_5.csv', 'WS23_L1_T1_P_6.csv', 'WS23_L1_T1_P_7.csv', 'WS23_L1_T1_P_8.csv', 'WS23_L1_T1_P_9.csv', 'WS23_L1_T1_P_10.csv', 'WS23_L1_T1_P_11.csv', 'WS23_L1_T1_P_12.csv', 'WS23_L1_T1_P_13.csv', 'WS23_L1_T1_P_14.csv', 'WS23_L1_T1_P_15.csv', 'WS23_L1_T1_P_16.csv', 'WS23_L1_T1_P_17.csv', 'WS23_L1_T1_P_18.csv', 'WS23_L1_T1_P_19.csv', 'WS23_L2_T1_P_0.csv', 'WS23_L2_T1_P_1.csv', 'WS23_L2_T1_P_2.csv', 'WS23_L2_T1_P_3.csv', 'WS23_L2_T1_P_4.csv', 'WS23_L2_T1_P_5.csv', 'WS23_L2_T1_P_6.csv', 'WS23_L2_T1_P_7.csv', 'WS23_L2_T1_P_8.csv', 'WS23_L2_T1_P_9.csv', 'WS23_L2_T1_P_10.csv', 'WS23_L2_T1_P_11.csv', 'WS23_L2_T1_P_12.csv', 'WS23_L2_T1_P_13.csv', 'WS23_L2_T1_P_14.csv', 'WS23_L2_T1_P_15.csv', 'WS23_L2_T1_P_16.csv', 'WS23_L2_T1_P_17.csv', 'WS23_L2_T2_P_0.csv', 'WS23_L2_T2_P_1.csv', 'WS23_L2_T2_P_2.csv', 'WS23_L2_T2_P_3.csv', 'WS23_L2_T2_P_4.csv', 'WS23_L3_T1_P_0.csv', 'WS23_L3_T1_P_1.csv', 'WS23_L3_T1_P_2.csv', 'WS23_L3_T1_P_3.csv', 'WS23_L3_T1_P_4.csv', 'WS23_L3_T1_P_5.csv', 'WS23_L3_T1_P_6.csv', 'WS23_L3_T1_P_7.csv', 'WS23_L3_T1_P_8.csv', 'WS23_L3_T1_P_9.csv', 'WS23_L3_T1_P_10.csv', 'WS23_L3_T1_P_11.csv', 'WS23_L3_T1_P_12.csv', 'WS23_L3_T1_P_13.csv', 'WS23_L3_T1_P_14.csv', 'WS23_L3_T1_P_15.csv', 'WS23_L3_T1_P_16.csv', 'WS23_L3_T1_P_17.csv', 'WS23_L3_T1_P_18.csv', 'WS23_L3_T1_P_19.csv', 'WS23_L3_T1_P_20.csv', 'WS23_L3_T1_P_21.csv', 'WS23_L3_T1_P_22.csv', 'WS23_L3_T1_P_23.csv']\n",
    "distances_list = [0, 3, 5.5, 10.5, 12, 14, 38, 41.5, 44, 47, 51, 90, 93, 96, 102, 107, 151, 152, 153, 170, 3.25, 0, 6, 13, 16, 19, 24, 64, 67, 72, 75, 87, 88, 88, 91, 95, 112, 116, 0, 4, 11, 20, 27, 0, 10, 16, 19, 40, 49, 98, 160, 161, 187, 188, 229, 253, 254, 255, 308, 317, 318, 353, 357, 363, 369, 384, 389]\n",
    "\n",
    "filenames_to_distances = dict(zip(filenames_list, distances_list))\n",
    "scaled_representations['distances'] = scaled_representations['filenames'].map(filenames_to_distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73a2c3f",
   "metadata": {},
   "source": [
    "# Save representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "248dd816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    depth_max  largest_force_drop_size  curve_first_quarter_slope  force_mean  \\\n",
      "0   -0.550657                -0.718540                  -0.466221   -0.098476   \n",
      "0    0.281633                 1.271706                  -0.371747   -0.168872   \n",
      "0    2.279623                 0.930300                  -0.601691   -1.512252   \n",
      "0    0.167589                 0.403249                  -0.385146   -0.966686   \n",
      "0    0.208086                 2.223877                  -0.618596   -0.962778   \n",
      "..        ...                      ...                        ...         ...   \n",
      "0   -1.417437                -1.006242                   1.470936    0.979564   \n",
      "0   -1.419996                -0.972782                   3.341502    2.254794   \n",
      "0    0.097455                 0.428395                  -0.516548    0.133144   \n",
      "0   -0.516263                -0.595287                  -0.281956   -0.007510   \n",
      "0   -0.664492                 2.094103                   0.492054    0.355218   \n",
      "\n",
      "    rsquared                       filenames marions_ylabels popcorn  \\\n",
      "0   0.140644             WS23_L1_T1_P_10.csv             NaN     NaN   \n",
      "0  -1.347093             WS23_L3_T1_P_10.csv            ES-D   False   \n",
      "0  -1.246300              WS23_L3_T1_P_6.csv           ES-BW    True   \n",
      "0  -0.273301              WS23_L3_T1_P_1.csv            ES-B    True   \n",
      "0  -1.194087              WS23_L3_T1_P_8.csv           ES-BW    True   \n",
      "..       ...                             ...             ...     ...   \n",
      "0   0.855325             WS23_L1_T1_P_20.csv             NaN     NaN   \n",
      "0   0.803022             WS23_L3_T1_P_22.csv              ES   False   \n",
      "0   0.746164             WS23_L1_T1_P_12.csv             NaN     NaN   \n",
      "0   0.381999  WS25_Aug5_Loc1A_T1_F9_0957.csv             NaN     NaN   \n",
      "0  -2.042314             WS23_L3_T1_P_21.csv              ES   False   \n",
      "\n",
      "    distances  \n",
      "0        51.0  \n",
      "0       188.0  \n",
      "0        98.0  \n",
      "0        10.0  \n",
      "0       161.0  \n",
      "..        ...  \n",
      "0         NaN  \n",
      "0       384.0  \n",
      "0        93.0  \n",
      "0         NaN  \n",
      "0       369.0  \n",
      "\n",
      "[110 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "scaled_representations.to_csv(f\"data/features.csv\", index=False)\n",
    "print(scaled_representations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env3.14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
