
thinking:
- overarching goal: use the robot dog to walk around and categorize the areas it traverses
- thus these different categories should each have their own unique type of force-depth plots (one category might have a crust break, others wont, ect)
- what if we cluster the curves into cateogies using unsupervised clustering techniques (clustering solely based on force-depth curve features -- not using any of Marion's labels and centroids)
    - then for each of these unsupervised naturally forming category
        - we look at photos corresponding to that cateogry and look for common visual features
- This will tell us what surface visual features actually matter. 


- so why are we using random visual features of the ground to map surface features to subsurface types.
- why are we even looking at the surface at all?
r   - can computer vision tie into  this?
    - the dogs penetration is
- why not use the do unsupervised learning on the curves to create the differnet subsurface catgeries.